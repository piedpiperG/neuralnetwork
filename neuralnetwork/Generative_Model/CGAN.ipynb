{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# CGAN"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf1c304bce122e87"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 导入库"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4dfb12544df3e0c5"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, datasets\n",
    "import numpy as np\n",
    "from torchvision.datasets import CIFAR10\n",
    "import torch.nn.init as init\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T11:21:18.992089800Z",
     "start_time": "2023-12-24T11:21:18.928036400Z"
    }
   },
   "id": "1540c907e0582a55"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 生成器的定义"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a08305ea0459e4ed"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "class ConditionalGenerator(nn.Module):\n",
    "    def __init__(self, latent_size, n_g_feature, n_channel, num_classes):\n",
    "        super(ConditionalGenerator, self).__init__()\n",
    "        self.label_emb = nn.Embedding(num_classes, latent_size)\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(latent_size * 2, 4 * n_g_feature, kernel_size=4, bias=False),\n",
    "            nn.BatchNorm2d(4 * n_g_feature),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(4 * n_g_feature, 2 * n_g_feature, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(2 * n_g_feature),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(2 * n_g_feature, n_g_feature, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(n_g_feature),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(n_g_feature, n_channel, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, z, labels):\n",
    "        c = self.label_emb(labels)\n",
    "        x = torch.cat([z, c.unsqueeze(2).unsqueeze(3)], 1)\n",
    "        return self.main(x)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T11:21:19.026089500Z",
     "start_time": "2023-12-24T11:21:18.945690400Z"
    }
   },
   "id": "6dc950b418dee35d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 判别器的定义"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db1d5bc0622ab7db"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "class ConditionalDiscriminator(nn.Module):\n",
    "    def __init__(self, n_channel, n_d_feature, num_classes):\n",
    "        super(ConditionalDiscriminator, self).__init__()\n",
    "        self.label_emb = nn.Embedding(num_classes, n_channel * 32 * 32)\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(n_channel + 1, n_d_feature, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(n_d_feature, 2 * n_d_feature, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(2 * n_d_feature),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(2 * n_d_feature, 4 * n_d_feature, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(4 * n_d_feature),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(4 * n_d_feature, 1, kernel_size=4)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "        c = self.label_emb(labels).view(x.size(0), 1, 32, 32)\n",
    "        x = torch.cat([x, c], 1)\n",
    "        return self.main(x)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T11:21:19.042088900Z",
     "start_time": "2023-12-24T11:21:18.962670300Z"
    }
   },
   "id": "8c9d28cac26833ea"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 数据加载\n",
    "加载 CIFAR-10 数据集并应用变换。\n",
    "使用 DataLoader 进行批处理和洗牌。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a640eed1a3df0f4"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset = CIFAR10(root='./CIFARdata', download=True, transform=transforms.ToTensor())\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T11:21:19.658318300Z",
     "start_time": "2023-12-24T11:21:18.975672100Z"
    }
   },
   "id": "b8ca21cb24fa854"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 初始化模型\n",
    "已经定义了ConditionalGenerator和ConditionalDiscriminator类。\n",
    "需要实例化这些类并应用权重初始化。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d18f6fbba4af4171"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "ConditionalDiscriminator(\n  (label_emb): Embedding(10, 3072)\n  (main): Sequential(\n    (0): Conv2d(4, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (1): LeakyReLU(negative_slope=0.2)\n    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (4): LeakyReLU(negative_slope=0.2)\n    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (7): LeakyReLU(negative_slope=0.2)\n    (8): Conv2d(256, 1, kernel_size=(4, 4), stride=(1, 1))\n  )\n)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型参数\n",
    "latent_size = 64  # 假设潜在空间维度为100\n",
    "n_channel = 3  # 图像通道数\n",
    "n_g_feature = 64  # 生成器特征数\n",
    "n_d_feature = 64  # 判别器特征数\n",
    "num_classes = 10  # CIFAR10的类别数\n",
    "\n",
    "# 创建生成器和判别器实例\n",
    "netG = ConditionalGenerator(latent_size, n_g_feature, n_channel, num_classes).to(device)\n",
    "netD = ConditionalDiscriminator(n_channel, n_d_feature, num_classes).to(device)\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    if type(m) in [nn.ConvTranspose2d, nn.Conv2d]:\n",
    "        init.xavier_normal_(m.weight)\n",
    "    elif type(m) == nn.BatchNorm2d:\n",
    "        init.normal_(m.weight, 1.0, 0.02)\n",
    "        init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "# 应用权重初始化\n",
    "netG.apply(weights_init)\n",
    "netD.apply(weights_init)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T11:21:19.735976200Z",
     "start_time": "2023-12-24T11:21:19.660318400Z"
    }
   },
   "id": "5eb8ed62d8ddc000"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 定义损失函数和优化器"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "12d494ef1ef3460d"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# 为生成器和判别器设置优化器\n",
    "optimizerG = torch.optim.Adam(netG.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizerD = torch.optim.Adam(netD.parameters(), lr=0.0002, betas=(0.5, 0.999))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T11:21:19.748976Z",
     "start_time": "2023-12-24T11:21:19.692319700Z"
    }
   },
   "id": "e078704646e70b31"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 训练循环"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1eff84a8fb3b12a"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[64, 1, 32, 32]' is invalid for input of size 196608",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[22], line 21\u001B[0m\n\u001B[0;32m     19\u001B[0m real_images \u001B[38;5;241m=\u001B[39m real_images\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     20\u001B[0m labels \u001B[38;5;241m=\u001B[39m labels\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m---> 21\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mnetD\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreal_images\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     22\u001B[0m d_loss_real \u001B[38;5;241m=\u001B[39m criterion(outputs, real_labels)\n\u001B[0;32m     23\u001B[0m d_loss_real\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[18], line 22\u001B[0m, in \u001B[0;36mConditionalDiscriminator.forward\u001B[1;34m(self, x, labels)\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, labels):\n\u001B[1;32m---> 22\u001B[0m     c \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlabel_emb\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mview\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msize\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     23\u001B[0m     x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat([x, c], \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     24\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmain(x)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: shape '[64, 1, 32, 32]' is invalid for input of size 196608"
     ]
    }
   ],
   "source": [
    "# 参数设置\n",
    "batch_size = 64\n",
    "fixed_noises = torch.randn(batch_size, latent_size, 1, 1)\n",
    "fixed_labels = torch.randint(0, num_classes, (batch_size,))\n",
    "\n",
    "# 初始化用于跟踪损失的列表\n",
    "d_losses = []\n",
    "g_losses = []\n",
    "\n",
    "# 训练循环\n",
    "epoch_num = 20\n",
    "for epoch in range(epoch_num):\n",
    "    for batch_idx, (real_images, labels) in enumerate(dataloader):\n",
    "        real_labels = torch.ones(batch_size, 1).to(device)\n",
    "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "        # 训练判别器\n",
    "        netD.zero_grad()\n",
    "        real_images = real_images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = netD(real_images, labels).view(-1)\n",
    "        d_loss_real = criterion(outputs, real_labels)\n",
    "        d_loss_real.backward()\n",
    "        D_x = outputs.sigmoid().mean()\n",
    "\n",
    "        # 生成假图像\n",
    "        noise = torch.randn(batch_size, latent_size, 1, 1, device=device)\n",
    "        fake_images = netG(noise, labels)\n",
    "        outputs = netD(fake_images.detach(), labels).view(-1)\n",
    "        d_loss_fake = criterion(outputs, fake_labels)\n",
    "        d_loss_fake.backward()\n",
    "        D_G_z1 = outputs.sigmoid().mean()\n",
    "\n",
    "        # 更新判别器\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        optimizerD.step()\n",
    "\n",
    "        # 训练生成器\n",
    "        netG.zero_grad()\n",
    "        outputs = netD(fake_images, labels).view(-1)\n",
    "        g_loss = criterion(outputs, real_labels)\n",
    "        g_loss.backward()\n",
    "        D_G_z2 = outputs.sigmoid().mean()\n",
    "        optimizerG.step()\n",
    "\n",
    "        # 记录损失\n",
    "        d_losses.append(d_loss.item())\n",
    "        g_losses.append(g_loss.item())\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(\n",
    "                f'Epoch [{epoch}/{epoch_num}] Batch {batch_idx}/{len(dataloader)} Loss D: {d_loss:.4f}, Loss G: {g_loss:.4f} D(x): {D_x:.4f} D(G(z)): {D_G_z1:.4f} / {D_G_z2:.4f}')\n",
    "\n",
    "            # 保存图像\n",
    "            with torch.no_grad():\n",
    "                fake = netG(fixed_noises.to(device), fixed_labels.to(device)).detach().to(device)\n",
    "                save_image(fake, f'./CGAN_saved/images_epoch{epoch:02d}_batch{batch_idx:03d}.png')\n",
    "\n",
    "# 绘制损失曲线\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(g_losses, label=\"Generator\")\n",
    "plt.plot(d_losses, label=\"Discriminator\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T11:21:19.801977600Z",
     "start_time": "2023-12-24T11:21:19.711976900Z"
    }
   },
   "id": "8eeb2510dc706470"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 保存模型"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b62ebb05259400a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 保存生成器和判别器\n",
    "generator_save_path = 'cgan_generator.pt'\n",
    "torch.save(netG.state_dict(), generator_save_path)\n",
    "\n",
    "discriminator_save_path = 'cgan_discriminator.pt'\n",
    "torch.save(netD.state_dict(), discriminator_save_path)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-24T11:21:19.802977300Z"
    }
   },
   "id": "b5f0a673542c215c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 加载模型"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f48eb4de8bce80d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 重新创建模型实例\n",
    "netG = ConditionalGenerator(latent_size, n_g_feature, n_channel, num_classes)\n",
    "netD = ConditionalDiscriminator(n_channel, n_d_feature, num_classes)\n",
    "\n",
    "# 加载保存的状态字典\n",
    "netG.load_state_dict(torch.load(generator_save_path))\n",
    "netD.load_state_dict(torch.load(discriminator_save_path))\n",
    "\n",
    "# 将模型设置为评估模式\n",
    "netG.eval()\n",
    "netD.eval()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T11:21:19.818671500Z",
     "start_time": "2023-12-24T11:21:19.804662Z"
    }
   },
   "id": "a34367d59610e460"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 进行评估"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "82da831c7b2f38a9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 生成图像以评估模型\n",
    "with torch.no_grad():\n",
    "    for i in range(100):\n",
    "        # 生成随机噪声和随机标签\n",
    "        noises = torch.randn(batch_size, latent_size, 1, 1)\n",
    "        random_labels = torch.randint(0, num_classes, (batch_size,))\n",
    "\n",
    "        # 生成图像\n",
    "        fake_images = netG(noises, random_labels).detach().to(device)\n",
    "\n",
    "        # 保存生成的图像\n",
    "        save_image(fake_images, f'./CGAN_Generated_Images/{i}.png')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-24T11:21:19.806671200Z"
    }
   },
   "id": "769d47af1c2f8739"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
