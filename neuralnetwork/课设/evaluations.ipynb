{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成的候选文本应该是如下结构：<br/>\n",
    "text = [\n",
    "    ['word11' ... 'word1n'],\n",
    "    ['word21' ... 'word2m'],\n",
    "    ...\n",
    "]里面可以包含特殊符号'\\<start\\>', '\\<end\\>', '\\<pad\\>'<br/>\n",
    "现在只考虑了一个输入只生成一个候选句子的情况，每个候选句子只有一个参考句子<br/>\n",
    "每个评测指标都是一个生成句子对应一个参考句子的指标值<br/>\n",
    "evaluation返回的是所有生成句子的评测指标的总平均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "def load_word_vectors(filename):\n",
    "    word_vectors = {}\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            word_vectors[word] = vector\n",
    "    return word_vectors\n",
    "\n",
    "\n",
    "# 加载词向量\n",
    "word_vectors = load_word_vectors('test_captions.json_word_vectors.txt')  # 替换为您的词向量文件路径\n",
    "\n",
    "\n",
    "def text_to_vectors(text, word_vectors):\n",
    "    # 转换为小写并移除标点\n",
    "    text = text.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "    words = text.split()\n",
    "    # 获取词向量的维度\n",
    "    vector_dim = len(next(iter(word_vectors.values())))\n",
    "\n",
    "    # 创建开始符和结束符的词向量\n",
    "    start_vector = np.ones(vector_dim)\n",
    "    end_vector = np.full(vector_dim, 2)\n",
    "\n",
    "    # 将开始符、词向量、结束符合并\n",
    "    vectors = [start_vector] + [word_vectors.get(word, np.zeros(vector_dim)) for word in words] + [end_vector]\n",
    "    return np.array(vectors), text\n",
    "\n",
    "\n",
    "class ImageTextDataset(Dataset):\n",
    "    def __init__(self, json_file_path, image_folder_path, word_vectors):\n",
    "        \"\"\"\n",
    "            Args:\n",
    "               json_file_path (string): JSON文件的路径，包含图片名称和对应的描述。\n",
    "               image_folder_path (string): 包含图片的文件夹路径。\n",
    "        \"\"\"\n",
    "        with open(json_file_path, 'r', encoding='utf-8') as file:\n",
    "            self.descriptions = json.load(file)\n",
    "        self.image_folder_path = image_folder_path\n",
    "        self.word_vectors = word_vectors\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.descriptions)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name, description = list(self.descriptions.items())[idx]\n",
    "        image_path = os.path.join(self.image_folder_path, image_name)\n",
    "\n",
    "        # 加载图像并调整尺寸\n",
    "        image = Image.open(image_path)\n",
    "        image = image.resize((750, 1101))  # 将图像大小调整为 750x1101\n",
    "\n",
    "        # 转换图像为numpy数组，然后转为Tensor\n",
    "        image = np.array(image)\n",
    "        if image.shape[2] == 4:  # 检查是否有alpha通道\n",
    "            image = image[..., :3]  # 仅保留RGB通道\n",
    "        image = torch.from_numpy(image).permute(2, 0, 1)  # 转换为CHW格式\n",
    "\n",
    "        # 处理文本描述\n",
    "        description_vectors, description = text_to_vectors(description, self.word_vectors)\n",
    "\n",
    "        return {'image': image, 'description_vectors': description_vectors, 'description': description}\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images = [item['image'] for item in batch]\n",
    "    description = [item['description'] for item in batch]\n",
    "    descriptions = [torch.tensor(item['description_vectors'], dtype=torch.float32) for item in batch]\n",
    "    descriptions_padded = pad_sequence(descriptions, batch_first=True, padding_value=0)\n",
    "    images = torch.stack(images, dim=0)  # 现在images是Tensor列表\n",
    "    return {'image': images, 'description_vectors': descriptions_padded, 'description': description}\n",
    "\n",
    "\n",
    "# 使用示例\n",
    "json_file_path = 'deepfashion-multimodal/test_captions.json'  # 替换为您的JSON文件路径\n",
    "image_folder_path = 'deepfashion-multimodal\\images'  # 替换为您的图片文件夹路径\n",
    "dataset = ImageTextDataset(json_file_path, image_folder_path, word_vectors)\n",
    "dataloader = DataLoader(dataset, batch_size=4, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "METEOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "函数代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32me:\\学\\大三上作业\\神经网络实验\\evaluations.ipynb 单元格 4\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E5%AD%A6/%E5%A4%A7%E4%B8%89%E4%B8%8A%E4%BD%9C%E4%B8%9A/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%AA%8C/evaluations.ipynb#W2sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     scores \u001b[39m=\u001b[39m [\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E5%AD%A6/%E5%A4%A7%E4%B8%89%E4%B8%8A%E4%BD%9C%E4%B8%9A/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%AA%8C/evaluations.ipynb#W2sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m         meteor_score\u001b[39m.\u001b[39mmeteor_score([ref], cand)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E5%AD%A6/%E5%A4%A7%E4%B8%89%E4%B8%8A%E4%BD%9C%E4%B8%9A/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%AA%8C/evaluations.ipynb#W2sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m         \u001b[39mfor\u001b[39;00m ref, cand \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(references, candidates)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E5%AD%A6/%E5%A4%A7%E4%B8%89%E4%B8%8A%E4%BD%9C%E4%B8%9A/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%AA%8C/evaluations.ipynb#W2sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     ]\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E5%AD%A6/%E5%A4%A7%E4%B8%89%E4%B8%8A%E4%BD%9C%E4%B8%9A/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%AA%8C/evaluations.ipynb#W2sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mmean(scores)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/%E5%AD%A6/%E5%A4%A7%E4%B8%89%E4%B8%8A%E4%BD%9C%E4%B8%9A/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%AA%8C/evaluations.ipynb#W2sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m evaluate_with_meteor(dataloader, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m)\n",
      "\u001b[1;32me:\\学\\大三上作业\\神经网络实验\\evaluations.ipynb 单元格 4\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E5%AD%A6/%E5%A4%A7%E4%B8%89%E4%B8%8A%E4%BD%9C%E4%B8%9A/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%AA%8C/evaluations.ipynb#W2sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m# multiple_refs = []\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E5%AD%A6/%E5%A4%A7%E4%B8%89%E4%B8%8A%E4%BD%9C%E4%B8%9A/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%AA%8C/evaluations.ipynb#W2sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m# for idx in range(len(refs)):\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E5%AD%A6/%E5%A4%A7%E4%B8%89%E4%B8%8A%E4%BD%9C%E4%B8%9A/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%AA%8C/evaluations.ipynb#W2sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m#     multiple_refs.append(refs[(idx//cpi)*cpi : (idx//cpi)*cpi+cpi])\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E5%AD%A6/%E5%A4%A7%E4%B8%89%E4%B8%8A%E4%BD%9C%E4%B8%9A/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%AA%8C/evaluations.ipynb#W2sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E5%AD%A6/%E5%A4%A7%E4%B8%89%E4%B8%8A%E4%BD%9C%E4%B8%9A/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%AA%8C/evaluations.ipynb#W2sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m# 计算 METEOR 分数\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E5%AD%A6/%E5%A4%A7%E4%B8%89%E4%B8%8A%E4%BD%9C%E4%B8%9A/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%AA%8C/evaluations.ipynb#W2sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m meteor_score_value \u001b[39m=\u001b[39m compute_meteor_score(refs, cands)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/%E5%AD%A6/%E5%A4%A7%E4%B8%89%E4%B8%8A%E4%BD%9C%E4%B8%9A/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%AA%8C/evaluations.ipynb#W2sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m model\u001b[39m.\u001b[39;49mtrain()\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E5%AD%A6/%E5%A4%A7%E4%B8%89%E4%B8%8A%E4%BD%9C%E4%B8%9A/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%AA%8C/evaluations.ipynb#W2sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39mreturn\u001b[39;00m meteor_score_value\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'train'"
     ]
    }
   ],
   "source": [
    "from nltk.translate import meteor_score\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def filter_useless_words(sent, filterd_words):\n",
    "    return [w for w in sent if w not in filterd_words]\n",
    "\n",
    "def evaluate_with_meteor(data_loader, model, config):\n",
    "    '''\n",
    "    data_loader : 数据集 {'image': image, 'description_vectors': description_vectors, 'description': description}\n",
    "    model : 模型\n",
    "    config : 有关数据集的信息，\n",
    "            config.captions_per_image 每个图片包含的描述数 \n",
    "            config.beam_k 用于束搜索（beam search）的参数，表示每个时间步保留的候选文本的数量。\n",
    "            config.max_len 生成文本的最大长度。\n",
    "    '''\n",
    "    # model.eval()\n",
    "    cands = []  # 存储候选文本\n",
    "    refs = []   # 存储参考文本\n",
    "    filterd_words = ['<start>', '<end>', '<pad>']\n",
    "    # cpi = config.captions_per_image\n",
    "    # device = next(model.parameters()).device\n",
    "\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        with torch.no_grad():\n",
    "            # 生成候选文本\n",
    "            texts = [des.split() for des in batch['description']] # 这是调试时用的，用参考文本先代替候选文本\n",
    "            # texts = model.generate_by_beamsearch(imgs.to(device), config.beam_k, config.max_len+2)\n",
    "            # 候选文本\n",
    "            for text in texts:\n",
    "                cands.append(filter_useless_words(text, filterd_words))\n",
    "            # 参考文本\n",
    "            for ref in batch['description']:\n",
    "                refs.append(filter_useless_words(ref.split(), filterd_words))\n",
    "\n",
    "    # multiple_refs = []\n",
    "    # for idx in range(len(refs)):\n",
    "    #     multiple_refs.append(refs[(idx//cpi)*cpi : (idx//cpi)*cpi+cpi])\n",
    "\n",
    "    # 计算 METEOR 分数\n",
    "    meteor_score_value = compute_meteor_score(refs, cands)\n",
    "    model.train()\n",
    "    return meteor_score_value\n",
    "\n",
    "def compute_meteor_score(references, candidates):\n",
    "    # 计算 METEOR 分数\n",
    "    scores = [\n",
    "        meteor_score.meteor_score([ref], cand)\n",
    "        for ref, cand in zip(references, candidates)\n",
    "    ]\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "evaluate_with_meteor(dataloader, None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROUGE-L 返回F值<br/>\n",
    "要 conda install rouge 或 pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\学\\大三上作业\\神经网络实验\\evaluations.ipynb 单元格 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/%E5%AD%A6/%E5%A4%A7%E4%B8%89%E4%B8%8A%E4%BD%9C%E4%B8%9A/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%AA%8C/evaluations.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m scores \u001b[39m=\u001b[39m [rouge\u001b[39m.\u001b[39mget_scores(hypothesis, ref) \u001b[39mfor\u001b[39;00m ref \u001b[39min\u001b[39;00m reference]\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/%E5%AD%A6/%E5%A4%A7%E4%B8%89%E4%B8%8A%E4%BD%9C%E4%B8%9A/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%AA%8C/evaluations.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m r \u001b[39m=\u001b[39m [s[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mrouge-l\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mp\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m scores]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/%E5%AD%A6/%E5%A4%A7%E4%B8%89%E4%B8%8A%E4%BD%9C%E4%B8%9A/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%AA%8C/evaluations.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m p \u001b[39m=\u001b[39m scores[:][\u001b[39m0\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mrouge-l\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39m\u001b[39mp\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E5%AD%A6/%E5%A4%A7%E4%B8%89%E4%B8%8A%E4%BD%9C%E4%B8%9A/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%AA%8C/evaluations.ipynb#W4sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m f \u001b[39m=\u001b[39m scores[:][\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mrouge-l\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E5%AD%A6/%E5%A4%A7%E4%B8%89%E4%B8%8A%E4%BD%9C%E4%B8%9A/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%AA%8C/evaluations.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(scores)\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge \n",
    "\n",
    "hypothesis = \"the #### transcript is a written version of each day 's cnn student news program use this transcript to he     lp students with reading comprehension and vocabulary use the weekly newsquiz to test your knowledge of storie s you     saw on cnn student news\"\n",
    "\n",
    "reference = [\"this page includes the show transcript use the transcript to help students with reading comprehension and\"  ,   \"vocabulary at the bottom of the page , comment for a chance to be mentioned on cnn student news . you must be a teac\" ,   \"her or a student age # # or older to request a mention on the cnn student news roll call . the weekly newsquiz tests\",     \"students ' knowledge of even ts in the news\"]\n",
    "\n",
    "rouge = Rouge(metrics=['rouge-l'])\n",
    "scores = [rouge.get_scores(hypothesis, ref) for ref in reference]\n",
    "r = [s[0]['rouge-l']['p'] for s in scores]\n",
    "\n",
    "p = scores[:][0]['rouge-l']['p']\n",
    "f = scores[:][0]['rouge-l']['f']\n",
    "print(scores)\n",
    "print(r)\n",
    "print(p)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32me:\\学\\大三上作业\\神经网络实验\\evaluations.ipynb 单元格 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E5%AD%A6/%E5%A4%A7%E4%B8%89%E4%B8%8A%E4%BD%9C%E4%B8%9A/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%AA%8C/evaluations.ipynb#W6sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m rouge \u001b[39m=\u001b[39m Rouge()\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E5%AD%A6/%E5%A4%A7%E4%B8%89%E4%B8%8A%E4%BD%9C%E4%B8%9A/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%AA%8C/evaluations.ipynb#W6sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# 计算 ROUGE 指标\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/%E5%AD%A6/%E5%A4%A7%E4%B8%89%E4%B8%8A%E4%BD%9C%E4%B8%9A/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%AA%8C/evaluations.ipynb#W6sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m scores \u001b[39m=\u001b[39m rouge\u001b[39m.\u001b[39;49mget_scores(hypothesis, references)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E5%AD%A6/%E5%A4%A7%E4%B8%89%E4%B8%8A%E4%BD%9C%E4%B8%9A/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%AA%8C/evaluations.ipynb#W6sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# 输出结果\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E5%AD%A6/%E5%A4%A7%E4%B8%89%E4%B8%8A%E4%BD%9C%E4%B8%9A/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%AA%8C/evaluations.ipynb#W6sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mprint\u001b[39m(scores)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\NetworkStudy\\lib\\site-packages\\rouge\\rouge.py:107\u001b[0m, in \u001b[0;36mRouge.get_scores\u001b[1;34m(self, hyps, refs, avg, ignore_empty)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[39massert\u001b[39;00m(\u001b[39mlen\u001b[39m(hyps) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(refs))\n\u001b[0;32m    106\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m avg:\n\u001b[1;32m--> 107\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_scores(hyps, refs)\n\u001b[0;32m    108\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_avg_scores(hyps, refs)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\NetworkStudy\\lib\\site-packages\\rouge\\rouge.py:116\u001b[0m, in \u001b[0;36mRouge._get_scores\u001b[1;34m(self, hyps, refs)\u001b[0m\n\u001b[0;32m    113\u001b[0m sen_score \u001b[39m=\u001b[39m {}\n\u001b[0;32m    115\u001b[0m hyp \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(_\u001b[39m.\u001b[39msplit()) \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m hyp\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(_) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m]\n\u001b[1;32m--> 116\u001b[0m ref \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(_\u001b[39m.\u001b[39msplit()) \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m ref\u001b[39m.\u001b[39;49msplit(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(_) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m]\n\u001b[0;32m    118\u001b[0m \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetrics:\n\u001b[0;32m    119\u001b[0m     fn \u001b[39m=\u001b[39m Rouge\u001b[39m.\u001b[39mAVAILABLE_METRICS[m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "\n",
    "# 生成的文本（hypothesis）\n",
    "hypothesis = \"This is a generated sentence.\"\n",
    "\n",
    "# 多个参考文本（reference）组成的列表\n",
    "references = [\n",
    "    \"This is a reference sentence 1.\",\n",
    "    \"This is a reference sentence 2.\",\n",
    "    \"This is a reference sentence 3.\"\n",
    "]\n",
    "\n",
    "# 初始化 Rouge 对象\n",
    "rouge = Rouge()\n",
    "\n",
    "# 计算 ROUGE 指标\n",
    "scores = rouge.get_scores(hypothesis, references)\n",
    "\n",
    "# 输出结果\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}], [{'rouge-l': {'r': 0.5, 'p': 0.5, 'f': 0.4999999950000001}}]]\n",
      "[['aa sd we we'], ['A BC D tt']]\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "\n",
    "def list_to_string(cand, ref):\n",
    "    return ' '.join(cand), ' '.join(ref)\n",
    "\n",
    "cand = ['A', 'B', 'C', 'D']\n",
    "muti_ref = [['aa', 'sd', 'we', 'we'], ['A', 'BC', 'D', 'tt']]\n",
    "\n",
    "rouge = Rouge(metrics=['rouge-l'])\n",
    "\n",
    "a = [[' '.join(ref)] for ref in muti_ref]\n",
    "rouge_L = [rouge.get_scores(' '.join(cand), ' '.join(ref)) for ref in muti_ref]\n",
    "print(rouge_L)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "函数代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32me:\\学\\大三上作业\\神经网络实验\\evaluations.ipynb 单元格 9\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E5%AD%A6/%E5%A4%A7%E4%B8%89%E4%B8%8A%E4%BD%9C%E4%B8%9A/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%AA%8C/evaluations.ipynb#W5sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m         scores\u001b[39m.\u001b[39mappend(f)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E5%AD%A6/%E5%A4%A7%E4%B8%89%E4%B8%8A%E4%BD%9C%E4%B8%9A/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%AA%8C/evaluations.ipynb#W5sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mmean(scores)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/%E5%AD%A6/%E5%A4%A7%E4%B8%89%E4%B8%8A%E4%BD%9C%E4%B8%9A/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%AA%8C/evaluations.ipynb#W5sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m evaluate_with_meteor(dataloader, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m)\n",
      "\u001b[1;32me:\\学\\大三上作业\\神经网络实验\\evaluations.ipynb 单元格 9\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E5%AD%A6/%E5%A4%A7%E4%B8%89%E4%B8%8A%E4%BD%9C%E4%B8%9A/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%AA%8C/evaluations.ipynb#W5sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m# 计算 ROUGE-L 分数\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E5%AD%A6/%E5%A4%A7%E4%B8%89%E4%B8%8A%E4%BD%9C%E4%B8%9A/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%AA%8C/evaluations.ipynb#W5sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m rouge_score_value \u001b[39m=\u001b[39m compute_rouge_score(refs, cands)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/%E5%AD%A6/%E5%A4%A7%E4%B8%89%E4%B8%8A%E4%BD%9C%E4%B8%9A/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%AA%8C/evaluations.ipynb#W5sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m model\u001b[39m.\u001b[39;49mtrain()\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E5%AD%A6/%E5%A4%A7%E4%B8%89%E4%B8%8A%E4%BD%9C%E4%B8%9A/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%AA%8C/evaluations.ipynb#W5sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39mreturn\u001b[39;00m rouge_score_value\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'train'"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def filter_useless_words(sent, filterd_words):\n",
    "    return [w for w in sent if w not in filterd_words]\n",
    "\n",
    "\n",
    "def list_to_string(cand, ref):\n",
    "    return ' '.join(cand), ' '.join(ref)\n",
    "\n",
    "\n",
    "def evaluate_with_rougeL(data_loader, model, config):\n",
    "    '''\n",
    "    data_loader : 数据集 {'image': image, 'description_vectors': description_vectors, 'description': description}\n",
    "    model : 模型\n",
    "    config : 有关数据集的信息，\n",
    "            config.captions_per_image 每个图片包含的描述数 \n",
    "            config.beam_k 用于束搜索（beam search）的参数，表示每个时间步保留的候选文本的数量。\n",
    "            config.max_len 生成文本的最大长度。\n",
    "    '''\n",
    "    # model.eval()\n",
    "    cands = []  # 存储候选文本\n",
    "    refs = []   # 存储参考文本\n",
    "    filterd_words = ['<start>', '<end>', '<pad>']\n",
    "    # cpi = config.captions_per_image\n",
    "    # device = next(model.parameters()).device\n",
    "\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        with torch.no_grad():\n",
    "            # 生成候选文本\n",
    "            texts = [des.split() for des in batch['description']] # 这是调试时用的，用参考文本先代替候选文本\n",
    "            # texts = model.generate_by_beamsearch(imgs.to(device), config.beam_k, config.max_len+2)\n",
    "            # 候选文本\n",
    "            for text in texts:\n",
    "                cands.append(filter_useless_words(text, filterd_words))\n",
    "            # 参考文本\n",
    "            for ref in batch['description']:\n",
    "                refs.append(filter_useless_words(ref.split(), filterd_words))\n",
    "\n",
    "    # 计算 ROUGE-L 分数\n",
    "    rouge_score_value = compute_rouge_score(refs, cands)\n",
    "    model.train()\n",
    "    return rouge_score_value\n",
    "\n",
    "def compute_rouge_score(references, candidates):\n",
    "    # 计算 ROUGE-L 分数\n",
    "    rouge = Rouge(metrics=['rouge-l'])\n",
    "    scores = []\n",
    "    for cand, ref in zip(candidates, references):\n",
    "        # 保证 cand 和 ref 都得是字符串才行\n",
    "        rouge_L = [rouge.get_scores(' '.join(cand), ' '.join(ref))]\n",
    "        # 取每个 ROUGE-L 的平均值？\n",
    "        f = np.mean([rl[0]['rouge-l']['f'] for rl in rouge_L])\n",
    "        scores.append(f)\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "evaluate_with_rougeL(dataloader, None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ciderD <br/>\n",
    "要 pip install git+https://github.com/michelecafagna26/cider.git#egg=cidereval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "感觉这个库计算的数值不大正常，迟点换pycoco的试一试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'avg_score': 1.132545730129139e-05, 'scores': array([1.13254573e-05])}, {'avg_score': 3.002962163221202e-05, 'scores': array([3.00296216e-05])}, {'avg_score': 1.918020994573542e-05, 'scores': array([1.91802099e-05])}]\n"
     ]
    }
   ],
   "source": [
    "from cidereval import cider, ciderD\n",
    "\n",
    "# refs and preds are lists of strings, the method will re-format them for you\n",
    "# 生成的文本（hypothesis）\n",
    "hypothesis =[\n",
    "    [\"This is a generated sentence.\"],\n",
    "    [\"This is a generated sentence.\"],\n",
    "    [\"This is a generated sentence.\"]\n",
    "]\n",
    "\n",
    "# 多个参考文本（reference）组成的列表\n",
    "references = [\n",
    "    [\"This is adsad reference sentence 1.\"],\n",
    "    [\"Thiadsds isadas a abd sentence 2.\"],\n",
    "    [\"Thisdas is a rcance sentence 3.\"]\n",
    "]\n",
    "\n",
    "\n",
    "a = [ciderD(predictions=hy, references=re, df='coco-val') for hy, re in zip(hypothesis,references)]\n",
    "#cider_scores is a dict-like object with \"avg_score\" and \"scores\"\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'avg_score': 0.030670514815346384, 'scores': array([0.035809  , 0.02742222, 0.02878032])}]\n"
     ]
    }
   ],
   "source": [
    "from cidereval import cider, ciderD\n",
    "\n",
    "# refs and preds are lists of strings, the method will re-format them for you\n",
    "\n",
    "references = [\n",
    "    \"This is reference 1.\",\n",
    "    \"This is reference 2.\",\n",
    "    \"This is reference 3.\"\n",
    "]\n",
    "\n",
    "predictions = [\n",
    "    \"This is a prediction for reference 1.\",\n",
    "    \"This is a prediction for reference 2.\",\n",
    "    \"This is a prediction for reference 3.\"\n",
    "]\n",
    "\n",
    "a = [ciderD(predictions=predictions, references=references, df='coco-val')]\n",
    "#cider_scores is a dict-like object with \"avg_score\" and \"scores\"\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'avg_score': 0.00959344110232026, 'scores': array([0.        , 0.        , 0.02878032])}]\n",
      "[{'avg_score': 0.015816910404604298, 'scores': array([0.        , 0.        , 0.04745073])}]\n"
     ]
    }
   ],
   "source": [
    "from cidereval import cider, ciderD\n",
    "\n",
    "# refs and preds are lists of strings, the method will re-format them for you\n",
    "\n",
    "references = [\n",
    "    \"This is reference 1.\",\n",
    "    \"This is reference 2.\",\n",
    "    \"This is reference 3.\"\n",
    "]\n",
    "\n",
    "predictions = [\n",
    "    \"This is a prediction for reference 3.\"\n",
    "]\n",
    "\n",
    "a = [ciderD(predictions=predictions * 3, references=references, df='coco-val')]\n",
    "b = [cider(predictions=predictions * 3, references=references)]\n",
    "#cider_scores is a dict-like object with \"avg_score\" and \"scores\"\n",
    "\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "函数代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avg_score': 5.826569362267109e-11, 'scores': array([2.85749833e-13, 4.94224528e-17, 2.25441072e-37, ...,\n",
      "       7.80027756e-18, 0.00000000e+00, 1.43228523e-20])} {'avg_score': 0.0, 'scores': array([0., 0., 0., ..., 0., 0., 0.])}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32me:\\学\\大三上作业\\神经网络实验\\evaluations.ipynb 单元格 14\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E5%AD%A6/%E5%A4%A7%E4%B8%89%E4%B8%8A%E4%BD%9C%E4%B8%9A/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%AA%8C/evaluations.ipynb#X22sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m     \u001b[39mprint\u001b[39m(cD, CD)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E5%AD%A6/%E5%A4%A7%E4%B8%89%E4%B8%8A%E4%BD%9C%E4%B8%9A/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%AA%8C/evaluations.ipynb#X22sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m cD\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/%E5%AD%A6/%E5%A4%A7%E4%B8%89%E4%B8%8A%E4%BD%9C%E4%B8%9A/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%AA%8C/evaluations.ipynb#X22sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m evaluate_with_ciderD(dataloader, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m)\n",
      "\u001b[1;32me:\\学\\大三上作业\\神经网络实验\\evaluations.ipynb 单元格 14\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E5%AD%A6/%E5%A4%A7%E4%B8%89%E4%B8%8A%E4%BD%9C%E4%B8%9A/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%AA%8C/evaluations.ipynb#X22sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m# multiple_refs = []\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E5%AD%A6/%E5%A4%A7%E4%B8%89%E4%B8%8A%E4%BD%9C%E4%B8%9A/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%AA%8C/evaluations.ipynb#X22sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39m# for idx in range(len(refs)):\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E5%AD%A6/%E5%A4%A7%E4%B8%89%E4%B8%8A%E4%BD%9C%E4%B8%9A/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%AA%8C/evaluations.ipynb#X22sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39m#     multiple_refs.append(refs[(idx//cpi)*cpi : (idx//cpi)*cpi+cpi])\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E5%AD%A6/%E5%A4%A7%E4%B8%89%E4%B8%8A%E4%BD%9C%E4%B8%9A/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%AA%8C/evaluations.ipynb#X22sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E5%AD%A6/%E5%A4%A7%E4%B8%89%E4%B8%8A%E4%BD%9C%E4%B8%9A/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%AA%8C/evaluations.ipynb#X22sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39m# 计算 CIDEr-D 分数\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E5%AD%A6/%E5%A4%A7%E4%B8%89%E4%B8%8A%E4%BD%9C%E4%B8%9A/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%AA%8C/evaluations.ipynb#X22sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m cider_score_value \u001b[39m=\u001b[39m compute_cider_score(refs, cands)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/%E5%AD%A6/%E5%A4%A7%E4%B8%89%E4%B8%8A%E4%BD%9C%E4%B8%9A/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%AA%8C/evaluations.ipynb#X22sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m model\u001b[39m.\u001b[39;49mtrain()\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E5%AD%A6/%E5%A4%A7%E4%B8%89%E4%B8%8A%E4%BD%9C%E4%B8%9A/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%AA%8C/evaluations.ipynb#X22sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39mreturn\u001b[39;00m cider_score_value\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'train'"
     ]
    }
   ],
   "source": [
    "from cidereval import ciderD\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def filter_useless_words(sent, filterd_words):\n",
    "    return [w for w in sent if w not in filterd_words]\n",
    "\n",
    "def list_to_string(cands, refs):\n",
    "    return [' '.join(cand) for cand in cands], [' '.join(ref) for ref in refs]\n",
    "\n",
    "\n",
    "def evaluate_with_ciderD(data_loader, model, config):\n",
    "    '''\n",
    "    data_loader : 数据集 {'image': image, 'description_vectors': description_vectors, 'description': description}\n",
    "    model : 模型\n",
    "    config : 有关数据集的信息，\n",
    "            config.captions_per_image 每个图片包含的描述数 \n",
    "            config.beam_k 用于束搜索（beam search）的参数，表示每个时间步保留的候选文本的数量。\n",
    "            config.max_len 生成文本的最大长度。\n",
    "    '''\n",
    "    # model.eval()\n",
    "    cands = []  # 存储候选文本\n",
    "    refs = []   # 存储参考文本\n",
    "    filterd_words = ['<start>', '<end>', '<pad>']\n",
    "    # cpi = config.captions_per_image\n",
    "    # device = next(model.parameters()).device\n",
    "\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        with torch.no_grad():\n",
    "            # 生成候选文本\n",
    "            texts = [des.split() for des in batch['description']] # 这是调试时用的，用参考文本先代替候选文本\n",
    "            # texts = model.generate_by_beamsearch(imgs.to(device), config.beam_k, config.max_len+2)\n",
    "            # 候选文本\n",
    "            for text in texts:\n",
    "                cands.append(filter_useless_words(text, filterd_words))\n",
    "            # 参考文本\n",
    "            for ref in batch['description']:\n",
    "                refs.append(filter_useless_words(ref.split(), filterd_words))\n",
    "\n",
    "    # multiple_refs = []\n",
    "    # for idx in range(len(refs)):\n",
    "    #     multiple_refs.append(refs[(idx//cpi)*cpi : (idx//cpi)*cpi+cpi])\n",
    "\n",
    "    # 计算 CIDEr-D 分数\n",
    "    cider_score_value = compute_cider_score(refs, cands)\n",
    "    model.train()\n",
    "    return cider_score_value\n",
    "\n",
    "\n",
    "def compute_cider_score(references, candidates):\n",
    "    # 计算 CIDEr-D 分数\n",
    "    scores = []\n",
    "    cands, refs = list_to_string(references, candidates)\n",
    "    # for cand, ref in zip(candidates, references):\n",
    "    #     # 将 cand 重复n遍，使其长度等于 muti_ref\n",
    "    #     cand = [' '.join(cand)] * len(muti_ref)\n",
    "    #     muti_ref = [' '.join(ref) for ref in muti_ref]\n",
    "    #     # 取 CIDEr-D 的平均值？\n",
    "    #     cD = ciderD(cand, muti_ref, df='coco-val')\n",
    "    #     scores.append(cD['avg_score'])\n",
    "    cD = ciderD(cands, refs, df = 'coco-val')\n",
    "    return cD['avg_score']\n",
    "\n",
    "\n",
    "evaluate_with_ciderD(dataloader, None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPICE <br/>\n",
    "用pycoco的库<br/>\n",
    "pip install pycocoevalcap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all references from dataset as references: dict\n",
    "# Collect all captions generated by model as captions: dict\n",
    "\n",
    "references = {\n",
    "    \"1\": [\"this is a tree\", \"this is an apple\"],\n",
    "    \"2\": [\"a man is sitting\", \"a man in the street\"],\n",
    "}\n",
    "\n",
    "captions = {\n",
    "    \"1\": [\"this is a big tree\"],\n",
    "    \"2\": [\"a man is sitting\"],\n",
    "}\n",
    "\n",
    "# Save them as correct json files\n",
    "import json\n",
    "\n",
    "new_cap = []\n",
    "for k, v in captions.items():\n",
    "    new_cap.append({'image_id': k, 'caption': v[0]})\n",
    "\n",
    "new_ref = {'images': [], 'annotations': []}\n",
    "for k, refs in references.items():\n",
    "    new_ref['images'].append({'id': k})\n",
    "    for ref in refs:\n",
    "        new_ref['annotations'].append({'image_id': k, 'id': k, 'caption': ref})\n",
    "\n",
    "with open('references.json', 'w') as fgts:\n",
    "    json.dump(new_ref, fgts)\n",
    "with open('captions.json', 'w') as fres:\n",
    "    json.dump(new_cap, fres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "\n",
    "def filter_useless_words(sent, filterd_words):\n",
    "    return [w for w in sent if w not in filterd_words]\n",
    "\n",
    "\n",
    "def save_json(cand, ref):\n",
    "    new_cap = []\n",
    "    for k, v in captions.items():\n",
    "        new_cap.append({'image_id': k, 'caption': v[0]})\n",
    "\n",
    "    new_ref = {'images': [], 'annotations': []}\n",
    "    for k, refs in references.items():\n",
    "        new_ref['images'].append({'id': k})\n",
    "        for ref in refs:\n",
    "            new_ref['annotations'].append({'image_id': k, 'id': k, 'caption': ref})\n",
    "\n",
    "    with open('references.json', 'w') as fgts:\n",
    "        json.dump(new_ref, fgts)\n",
    "    with open('captions.json', 'w') as fres:\n",
    "        json.dump(new_cap, fres)\n",
    "\n",
    "\n",
    "def evaluate_with_meteor(data_loader, model, config):\n",
    "    model.eval()\n",
    "    cands = {}  # 存储候选文本\n",
    "    refs = {}   # 存储参考文本\n",
    "    filterd_words = set({model.vocab['<start>'], model.vocab['<end>'], model.vocab['<pad>']})\n",
    "    cpi = config.captions_per_image\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    for i, (imgs, caps, caplens) in enumerate(data_loader):\n",
    "        with torch.no_grad():\n",
    "            # 生成参考文本\n",
    "            texts = model.generate_by_beamsearch(imgs.to(device), config.beam_k, config.max_len+2)\n",
    "            # 候选文本\n",
    "            cands[f'{i}'] = [filter_useless_words(text, filterd_words) for text in texts]\n",
    "            # 参考文本\n",
    "            refs[f'{i}'] = [filter_useless_words(cap, filterd_words) for cap in caps.tolist()]\n",
    "\n",
    "    multiple_refs = {}\n",
    "    for idx in range(len(refs)):\n",
    "        multiple_refs.append(refs[(idx//cpi)*cpi : (idx//cpi)*cpi+cpi])\n",
    "\n",
    "    # 计算 CIDEr-D 分数\n",
    "    spice_score_value = compute_spice_score(multiple_refs, cands)\n",
    "    model.train()\n",
    "    return spice_score_value\n",
    "\n",
    "\n",
    "def compute_spice_score(references, candidates):\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NetworkStudy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
